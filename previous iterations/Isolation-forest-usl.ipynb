{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86d409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 544464  428317]\n",
      " [3577414  348236]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1321    0.5597    0.2137    972781\n",
      "           1     0.4484    0.0887    0.1481   3925650\n",
      "\n",
      "    accuracy                         0.1822   4898431\n",
      "   macro avg     0.2903    0.3242    0.1809   4898431\n",
      "weighted avg     0.3856    0.1822    0.1611   4898431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load preprocessed data\n",
    "X_processed = np.load(\"dataset/X_processed.npy\")\n",
    "y_true = np.load(\"dataset/y_true.npy\")\n",
    "\n",
    "# Initialize and train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination='auto',\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "iso_forest.fit(X_processed)\n",
    "\n",
    "# Predict anomaly scores (-1 for anomaly, 1 for normal)\n",
    "y_pred_raw = iso_forest.predict(X_processed)\n",
    "\n",
    "# Convert to binary format (1 = anomaly, 0 = normal)\n",
    "y_pred = (y_pred_raw == -1).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ad50d",
   "metadata": {},
   "source": [
    "##### Trained an unsupervised Isolation Forest model on the preprocessed data. The baseline showed **low accuracy (\\~18%)** and **poor recall for attacks (\\~9%)**, indicating it missed many anomalies. Since performance was insufficient, we proceeded to **Step 4A.2: Hyperparameter tuning** to improve detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c87d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with contamination=0.1, max_samples=auto, n_estimators=100\n",
      "\n",
      "Training with contamination=0.1, max_samples=auto, n_estimators=200\n",
      "\n",
      "Training with contamination=0.1, max_samples=0.2, n_estimators=100\n",
      "\n",
      "Training with contamination=0.1, max_samples=0.2, n_estimators=200\n",
      "\n",
      "Training with contamination=0.1, max_samples=0.5, n_estimators=100\n",
      "\n",
      "Training with contamination=0.1, max_samples=0.5, n_estimators=200\n",
      "\n",
      "Training with contamination=0.2, max_samples=auto, n_estimators=100\n",
      "\n",
      "Training with contamination=0.2, max_samples=auto, n_estimators=200\n",
      "\n",
      "Training with contamination=0.2, max_samples=0.2, n_estimators=100\n",
      "\n",
      "Training with contamination=0.2, max_samples=0.2, n_estimators=200\n",
      "\n",
      "Training with contamination=0.2, max_samples=0.5, n_estimators=100\n",
      "\n",
      "Training with contamination=0.2, max_samples=0.5, n_estimators=200\n",
      "\n",
      "Training with contamination=0.3, max_samples=auto, n_estimators=100\n",
      "\n",
      "Training with contamination=0.3, max_samples=auto, n_estimators=200\n",
      "\n",
      "Training with contamination=0.3, max_samples=0.2, n_estimators=100\n",
      "\n",
      "Training with contamination=0.3, max_samples=0.2, n_estimators=200\n",
      "\n",
      "Training with contamination=0.3, max_samples=0.5, n_estimators=100\n",
      "\n",
      "Training with contamination=0.3, max_samples=0.5, n_estimators=200\n",
      "\n",
      " Best Configuration Found:\n",
      "{'contamination': 0.3, 'max_samples': 'auto', 'n_estimators': 200}\n",
      "Best F1-score (attack class): 0.3289\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "contamination_vals = [0.1, 0.2, 0.3]\n",
    "max_samples_vals = ['auto', 0.2, 0.5]\n",
    "n_estimators_vals = [100, 200]\n",
    "\n",
    "# Track best configuration\n",
    "best_f1 = 0\n",
    "best_params = {}\n",
    "all_results = []\n",
    "\n",
    "# Manual tuning loop\n",
    "for contamination in contamination_vals:\n",
    "    for max_samples in max_samples_vals:\n",
    "        for n_estimators in n_estimators_vals:\n",
    "            print(f\"\\nTraining with contamination={contamination}, max_samples={max_samples}, n_estimators={n_estimators}\")\n",
    "\n",
    "            # Train model\n",
    "            model = IsolationForest(\n",
    "                contamination=contamination,\n",
    "                max_samples=max_samples,\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "                n_jobs=-1\n",
    "\n",
    "            )\n",
    "            model.fit(X_processed)\n",
    "\n",
    "            # Predict: -1 = anomaly, 1 = normal\n",
    "            y_pred_raw = model.predict(X_processed)\n",
    "            y_pred = (y_pred_raw == -1).astype(int)\n",
    "\n",
    "            # Evaluate performance\n",
    "            report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "            f1 = report['1']['f1-score']\n",
    "            recall = report['1']['recall']\n",
    "            precision = report['1']['precision']\n",
    "\n",
    "            # Store results\n",
    "            all_results.append({\n",
    "                'contamination': contamination,\n",
    "                'max_samples': max_samples,\n",
    "                'n_estimators': n_estimators,\n",
    "                'f1': f1,\n",
    "                'recall': recall,\n",
    "                'precision': precision\n",
    "            })\n",
    "\n",
    "            # Update best\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = {\n",
    "                    'contamination': contamination,\n",
    "                    'max_samples': max_samples,\n",
    "                    'n_estimators': n_estimators\n",
    "                }\n",
    "\n",
    "# Display best configuration\n",
    "print(\"\\n Best Configuration Found:\")\n",
    "print(best_params)\n",
    "print(f\"Best F1-score (attack class): {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717605f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Evaluation on Full Data:\n",
      "Confusion Matrix:\n",
      "[[ 391241  581540]\n",
      " [3038633  887017]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.40      0.18    972781\n",
      "           1       0.60      0.23      0.33   3925650\n",
      "\n",
      "    accuracy                           0.26   4898431\n",
      "   macro avg       0.36      0.31      0.25   4898431\n",
      "weighted avg       0.51      0.26      0.30   4898431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/isolation_forest_final.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Best parameters from tuning\n",
    "final_model = IsolationForest(\n",
    "    contamination=best_params['contamination'],\n",
    "    max_samples=best_params['max_samples'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train on full data\n",
    "final_model.fit(X_processed)\n",
    "\n",
    "# Predict anomalies\n",
    "y_pred_final_raw = final_model.predict(X_processed)\n",
    "y_pred_final = (y_pred_final_raw == -1).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n Final Evaluation on Full Data:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_final))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_final, zero_division=0))\n",
    "\n",
    "# Optional: Save the model\n",
    "joblib.dump(final_model, 'models/isolation_forest_final.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a76e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Isolation Forest Final Evaluation:\n",
      "Confusion Matrix:\n",
      "[[ 391241  581540]\n",
      " [3038633  887017]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.40      0.18    972781\n",
      "           1       0.60      0.23      0.33   3925650\n",
      "\n",
      "    accuracy                           0.26   4898431\n",
      "   macro avg       0.36      0.31      0.25   4898431\n",
      "weighted avg       0.51      0.26      0.30   4898431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Best hyperparameters found from tuning\n",
    "best_params = {\n",
    "    'contamination': 0.3,\n",
    "    'max_samples': 'auto',\n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso_model = IsolationForest(\n",
    "    contamination=best_params['contamination'],\n",
    "    max_samples=best_params['max_samples'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "iso_model.fit(X_processed)\n",
    "\n",
    "\n",
    "y_pred_iso = (iso_model.predict(X_processed) == -1).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Isolation Forest Final Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_iso))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_iso, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
